{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUjMZpdFW_pf",
        "outputId": "e8686693-8cda-4abd-e6c0-fe96c7ba3588"
      },
      "source": [
        "# some basic things to include\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import pathlib\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# some preprocessing techniques\n",
        "from scipy.fftpack import dct\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "# this is only required for Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpnqQ6tWKQ1W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKe-aheLY_C7"
      },
      "source": [
        "'''\n",
        "Usage:\n",
        "as image preprocessor by calling DCT() as a transform\n",
        "\n",
        "input: 128*128*3 PIL image\n",
        "output: 64*256 torch array (histogram)\n",
        "\n",
        "[128*128] => (crop) => [256 * [8*8]] => (DCT_2d) => [256 * [8 * 8]] => reshape => [256 * 64]  \n",
        "'''\n",
        "class DCT(object):\n",
        "    def __init__(self):\n",
        "        self.BLOCK_HEIGHT = 8\n",
        "        self.BLOCK_WIDTH = 8\n",
        "        self.BLOCK_SIZE = (self.BLOCK_HEIGHT, self.BLOCK_WIDTH)\n",
        "\n",
        "    def div_block(self, img, block_size):\n",
        "        img_height = img.height\n",
        "        img_width = img.width\n",
        "        block_height = block_size[0]\n",
        "        block_width = block_size[1]\n",
        "        assert(img_height % block_height == 0)\n",
        "        assert(img_width % block_width == 0)\n",
        "\n",
        "        blocks = []\n",
        "        for i in range(0,img_height,block_height):\n",
        "            for j in range(0,img_width,block_width):\n",
        "                box = (j, i, j+block_width, i+block_height)\n",
        "                block = np.array(img.crop(box))\n",
        "                blocks.append(block)\n",
        "        return np.array(blocks)\n",
        "\n",
        "    def dct2(self, array_2d):\n",
        "        return dct(dct(array_2d.T, norm = 'ortho').T, norm = 'ortho')\n",
        "\n",
        "    def _dct2(self, array_2d):\n",
        "        return dct(dct(array_2d, norm = 'ortho').T, norm = 'ortho').T\n",
        "\n",
        "    def __call__(self, img):\n",
        "        image = img\n",
        "        blocks = self.div_block(image, self.BLOCK_SIZE)\n",
        "        b_blocks, g_blocks, r_blocks = blocks[:, :, :, 0], blocks[:, :, :, 1], blocks[:, :, :, 2]\n",
        "        test_blocks = (b_blocks + g_blocks + r_blocks) / 3 # naive greyscale\n",
        "        result = np.array([self._dct2(test_block) for test_block in test_blocks])\n",
        "        # return a torch.tensor\n",
        "        return torch.from_numpy(result.reshape(256, 64).T).float()\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"Simply DCT. What do you expect?\"\n",
        "\n",
        "'''\n",
        "Usage: Same as DCT()\n",
        "\n",
        "input: 64*256 torch array (histogram)\n",
        "output: 64*256 torch array (frequency histogram)\n",
        "'''\n",
        "class DFT(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, freq):\n",
        "        # convert into complex form containing real and imaginary part\n",
        "        cmplx = torch.from_numpy(np.zeros((freq.shape[0], freq.shape[1], 2)))\n",
        "        cmplx[:, :, 0] += freq\n",
        "        out = torch.fft(cmplx, 1)[:, :, 0]\n",
        "        return out\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"Simply DFT. What do you expect?\"\n",
        "\n",
        "class Ycbcr_convert():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, img):\n",
        "        return img.convert('YCbCr')\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"Convert a PIL Image from RGB to YCbCr\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbYvo1eSZDJl",
        "outputId": "39ea000a-0c37-4e8d-f428-9ec115e6f90b"
      },
      "source": [
        "def image_show(np_image):\n",
        "    plt.figure(figsize = (5,5))\n",
        "    plt.imshow(np_image) # it should be a numpy array\n",
        "    plt.show()\n",
        "\n",
        "# mainfolder = 'drive/My Drive/COMP5331 Fall 2020/MM17-WeiboRumorSet/'\n",
        "\n",
        "#mainfolder = 'MM17-WeiboRumorSet/'\n",
        "train_path='/content/drive/MyDrive/colab_data/train/'\n",
        "test_path='/content/drive/MyDrive/colab_data/test/'\n",
        "\n",
        "image_height = 128\n",
        "image_width  = 128\n",
        "mytransform = transforms.Compose([\n",
        "    transforms.Resize((image_height,image_width), interpolation=Image.BICUBIC),\n",
        "    Ycbcr_convert(),\n",
        "    DCT(),\n",
        "    # DFT()\n",
        "])\n",
        "\n",
        "#dataset = datasets.ImageFolder(mainfolder, transform=mytransform) \n",
        "trainset = datasets.ImageFolder(train_path, transform=mytransform)\n",
        "testset = datasets.ImageFolder(test_path, transform=mytransform)\n",
        "# NOTE: The path should point to a place with subfolders (which contain images inside).\n",
        "#  It will report bugs if there is no subfolder.\n",
        "# print(type(dataset))\n",
        "#print('Total no. of images: ', len(trainset))\n",
        "print('Total no. of images: ', len(testset))\n",
        "\n",
        "#print(round(len(dataset)*0.5))\n",
        "\n",
        "# 50% train, 50% test\n",
        "#trainset, testset = torch.utils.data.random_split(dataset, [round(len(dataset)*0.8), round(len(dataset)*0.2)])\n",
        "print('Total no. of train set images: ', len(trainset))\n",
        "print('Total no. of test set images: ', len(testset))\n",
        "\n",
        "#labels = dataset.class_to_idx # the dataset saves the subfolder's name as the labels\n",
        "# print(labels) \n",
        "# print(type(labels))\n",
        "\n",
        "#classes = list(labels.keys()) # convert dict keys into list\n",
        "root=pathlib.Path(train_path)\n",
        "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
        "print('classes:', classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total no. of images:  3662\n",
            "Total no. of train set images:  14459\n",
            "Total no. of test set images:  3662\n",
            "classes: ['Boredom', 'Confusion', 'Engagement', 'Frustration']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y8dVT0RbNJm",
        "outputId": "8fad3a80-2ab9-4483-f883-2867cb9641ab"
      },
      "source": [
        "print(type(testset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torchvision.datasets.folder.ImageFolder'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPSdXlHdZEiN"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True) \n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL_IgFFtXA6g",
        "outputId": "f1d51b61-dd03-4f9f-d8e5-02f0aa30600f"
      },
      "source": [
        "print(type(testloader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.utils.data.dataloader.DataLoader'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJzalJ3-ZXyk"
      },
      "source": [
        "class Frequent_Domain_Subnetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Frequent_Domain_Subnetwork, self).__init__()\n",
        "        self.backbone = nn.Sequential(nn.Conv1d(64, 32, 3, padding=1),\n",
        "                             nn.BatchNorm1d(32),\n",
        "                             nn.ReLU(),\n",
        "                             nn.MaxPool1d(2),\n",
        "                             nn.Conv1d(32, 64, 3, padding=1),\n",
        "                             nn.BatchNorm1d(64),\n",
        "                             nn.ReLU(),\n",
        "                             nn.MaxPool1d(2),\n",
        "                             nn.Conv1d(64, 128, 3, padding=1),\n",
        "                             nn.BatchNorm1d(128),\n",
        "                             nn.ReLU(),\n",
        "                             nn.MaxPool1d(2),\n",
        "                             nn.Flatten(),\n",
        "                             nn.Linear(4096, 64),\n",
        "                             nn.ReLU(),\n",
        "                             nn.Linear(64, 64))\n",
        "        #self.Wc = nn.Linear(64, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.backbone.forward(x)\n",
        "        return out\n",
        "\n",
        "    #def forward(self, x_pixel, x_freq):\n",
        "\n",
        "        #L0 = self.freq_subnet(x_freq)  # Bx64\n",
        "        #out = self.Wc(L0) # final output: Bx2\n",
        "        #return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMg6IRcSZbqA"
      },
      "source": [
        "MAX_EPOCH = 5\n",
        "print_every = 20\n",
        "\n",
        "device = 'cpu'\n",
        "model = Frequent_Domain_Subnetwork().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)\n",
        "\n",
        "\n",
        "# Hyper-parameters\n",
        "MAX_EPOCH = 10\n",
        "learning_rate = 0.0001 # adopt a small lr to ensure convergence\n",
        "batch_size = 32\n",
        "resumetraining = False\n",
        "\n",
        "print_every = 20\n",
        "test_n_savemodel_every_epoch = 2\n",
        "#device = 'cuda'\n",
        "seed_no = 0\n",
        "stop_at_loss = 0.1    #before it was 0.1. But it is not very stable.\n",
        "#================================\n",
        "modelname = 'MVNN_wout_freq'    # Which model to use?\n",
        "#================================"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr0fJlQIZdqR"
      },
      "source": [
        "from sklearn.metrics import accuracy_score # normal accuracy\n",
        "from sklearn.metrics import balanced_accuracy_score # used in case of imbalanced data sets, average of recall, from 0 to 1\n",
        "from sklearn.metrics import confusion_matrix # division of performance on the multilabels\n",
        "from sklearn.metrics import cohen_kappa_score # compares model against random prediction, from -1 to 1\n",
        "from sklearn.metrics import classification_report # for multilabel classification, gives precision, recall, f score, support, more\n",
        "\n",
        "def print_metrics(y_true, y_pred, target_names):\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Balanced Accuracy:\" , balanced_accuracy_score(y_true, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "    print(\"Cohen Kappa Score:\", cohen_kappa_score(y_true, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_true, y_pred, target_names=target_names))\n",
        "\n",
        "#  function to view one image\n",
        "def image_show(np_image):\n",
        "  plt.figure(figsize = (5,5))\n",
        "  plt.imshow(np_image) # it should be a numpy array\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2ZbkjSeZfzh",
        "outputId": "5cbfa3e1-f66a-4627-e325-431d3d0307e5"
      },
      "source": [
        "for epoch in range(MAX_EPOCH):\n",
        "    total_loss, total_acc = 0, 0\n",
        "    cnt = 0\n",
        "    for i, data in enumerate(trainloader):\n",
        "        X, y = data[0].float().to(device), data[1].to(device)\n",
        "        optimizer.zero_grad() \n",
        "       \n",
        "        # forward\n",
        "        out = model(X)        \n",
        "        #print(out, y_pred)\n",
        "        loss = criterion(out, y)\n",
        "\n",
        "        # backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # stats\n",
        "        y_pred = torch.argmax(out, dim=1)\n",
        "        total_acc += (y_pred == y).sum().item() / len(y_pred)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        cnt += 1\n",
        "        if i % print_every == 0:\n",
        "            avg_loss = total_loss / cnt\n",
        "            avg_acc = total_acc / cnt\n",
        "            total_acc, total_loss = 0, 0\n",
        "            cnt = 0\n",
        "            # print(out.T, '\\n', y_pred.T, '\\n', y.T)\n",
        "            print('[Epoch %d Iter %d] Loss: %5f  Acc: %5f' % (epoch+1, i+1, avg_loss, avg_acc))\n",
        "    # Validating\n",
        "    '''if (epoch+1) % test_n_savemodel_every_epoch == 0:\n",
        "      report_every = 10\n",
        "      test_loss = 0\n",
        "      cnt = 0\n",
        "      model.eval()\n",
        "      y_true = []\n",
        "      y_pred = []\n",
        "      with torch.no_grad():\n",
        "          print('\\n===== Start Validating ... =====')\n",
        "          for data in testloader:\n",
        "              Xp, Xf = data[0].float().to(device), data[1].float().to(device)\n",
        "              y = data[0].to(device)\n",
        "\n",
        "              # prediction\n",
        "              out = model(Xp, Xf)        \n",
        "              pred = torch.argmax(out, dim=1)\n",
        "\n",
        "              loss = criterion(out, y)\n",
        "              test_loss += loss.item()\n",
        "\n",
        "              y_true.append(y)\n",
        "              y_pred.append(pred)\n",
        "\n",
        "              cnt += 1\n",
        "\n",
        "              if cnt % report_every == 0:\n",
        "                  print(\"[Test] [Epoch %d]  %d / %d batches tested\" % (epoch+1, cnt, testloader.__len__()))        \n",
        "\n",
        "          test_loss = test_loss/cnt\n",
        "          print(\"[Test] [Epoch %d] %d / %d batches tested. Test Loss: %5f\" % (epoch+1, cnt, testloader.__len__(), test_loss))\n",
        "      model.train() # Toggle on the training mode to enable back the dropout/batchnorm layers for training\n",
        "      \n",
        "      # Print classification report\n",
        "      y_true = torch.cat(y_true, dim=0)\n",
        "      y_pred = torch.cat(y_pred, dim=0)\n",
        "      target_names = ['Boredom', 'Confusion', 'Engagement', 'Frustration']\n",
        "      print_metrics(y_true.cpu(), y_pred.cpu(), target_names)\n",
        "      print('')\n",
        "\n",
        "      # Save model checkpoint\n",
        "      PATH = ('drive/My Drive/Colab Notebooks/trained_models/' + modelname + \"_MAXepoch\" + str(MAX_EPOCH)\n",
        "              + \"_batch\" + str(batch_size) + \"_lr\" + str(learning_rate) + '_seed' + str(seed_no) + \".pth\")\n",
        "      print(PATH)\n",
        "      torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': criterion,\n",
        "            'epoch_acc': epoch_acc,\n",
        "            'epoch_loss': epoch_loss,\n",
        "            }, PATH)\n",
        "      print('!!! The trained model is saved !!!') # Make sure you have enough space on google drive\n",
        "\n",
        "    # Early stopper\n",
        "    #if running_loss < stop_at_loss:\n",
        "      #print('Training is stopped at [Epoch %d] as loss is already very low (%5f)!' %(epoch+1, running_loss))\n",
        "      #break\n",
        "\n",
        "print('\\n===== Finished Training & Validating =====')\n",
        "'''\n",
        "# save the model somewhere\n",
        "torch.save(model.state_dict(), \"model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1 Iter 1] Loss: 4.126261  Acc: 0.000000\n",
            "[Epoch 1 Iter 21] Loss: 1.753894  Acc: 0.496875\n",
            "[Epoch 1 Iter 41] Loss: 1.018311  Acc: 0.637500\n",
            "[Epoch 1 Iter 61] Loss: 0.976918  Acc: 0.635938\n",
            "[Epoch 1 Iter 81] Loss: 0.907277  Acc: 0.648438\n",
            "[Epoch 1 Iter 101] Loss: 0.944477  Acc: 0.657813\n",
            "[Epoch 1 Iter 121] Loss: 0.901147  Acc: 0.675000\n",
            "[Epoch 1 Iter 141] Loss: 0.935786  Acc: 0.639062\n",
            "[Epoch 1 Iter 161] Loss: 0.924929  Acc: 0.681250\n",
            "[Epoch 1 Iter 181] Loss: 0.841995  Acc: 0.671875\n",
            "[Epoch 1 Iter 201] Loss: 0.919518  Acc: 0.656250\n",
            "[Epoch 1 Iter 221] Loss: 0.810133  Acc: 0.693750\n",
            "[Epoch 1 Iter 241] Loss: 0.831985  Acc: 0.685937\n",
            "[Epoch 1 Iter 261] Loss: 0.817299  Acc: 0.684375\n",
            "[Epoch 1 Iter 281] Loss: 0.847840  Acc: 0.657813\n",
            "[Epoch 1 Iter 301] Loss: 0.826316  Acc: 0.709375\n",
            "[Epoch 1 Iter 321] Loss: 0.795262  Acc: 0.715625\n",
            "[Epoch 1 Iter 341] Loss: 0.784903  Acc: 0.703125\n",
            "[Epoch 1 Iter 361] Loss: 0.800849  Acc: 0.693750\n",
            "[Epoch 1 Iter 381] Loss: 0.799522  Acc: 0.695312\n",
            "[Epoch 1 Iter 401] Loss: 0.813500  Acc: 0.701562\n",
            "[Epoch 1 Iter 421] Loss: 0.836339  Acc: 0.671875\n",
            "[Epoch 1 Iter 441] Loss: 0.823885  Acc: 0.689063\n",
            "[Epoch 2 Iter 1] Loss: 0.733400  Acc: 0.718750\n",
            "[Epoch 2 Iter 21] Loss: 0.831583  Acc: 0.665625\n",
            "[Epoch 2 Iter 41] Loss: 0.805201  Acc: 0.690625\n",
            "[Epoch 2 Iter 61] Loss: 0.782103  Acc: 0.700000\n",
            "[Epoch 2 Iter 81] Loss: 0.800776  Acc: 0.676562\n",
            "[Epoch 2 Iter 101] Loss: 0.785307  Acc: 0.685937\n",
            "[Epoch 2 Iter 121] Loss: 0.759249  Acc: 0.706250\n",
            "[Epoch 2 Iter 141] Loss: 0.799069  Acc: 0.696875\n",
            "[Epoch 2 Iter 161] Loss: 0.782453  Acc: 0.684375\n",
            "[Epoch 2 Iter 181] Loss: 0.847806  Acc: 0.664062\n",
            "[Epoch 2 Iter 201] Loss: 0.779342  Acc: 0.703125\n",
            "[Epoch 2 Iter 221] Loss: 0.760573  Acc: 0.725000\n",
            "[Epoch 2 Iter 241] Loss: 0.778027  Acc: 0.706250\n",
            "[Epoch 2 Iter 261] Loss: 0.742434  Acc: 0.718750\n",
            "[Epoch 2 Iter 281] Loss: 0.723813  Acc: 0.710938\n",
            "[Epoch 2 Iter 301] Loss: 0.770359  Acc: 0.704688\n",
            "[Epoch 2 Iter 321] Loss: 0.767353  Acc: 0.695312\n",
            "[Epoch 2 Iter 341] Loss: 0.742517  Acc: 0.715625\n",
            "[Epoch 2 Iter 361] Loss: 0.760573  Acc: 0.701562\n",
            "[Epoch 2 Iter 381] Loss: 0.799227  Acc: 0.687500\n",
            "[Epoch 2 Iter 401] Loss: 0.764659  Acc: 0.706250\n",
            "[Epoch 2 Iter 421] Loss: 0.759558  Acc: 0.700000\n",
            "[Epoch 2 Iter 441] Loss: 0.704252  Acc: 0.732812\n",
            "[Epoch 3 Iter 1] Loss: 0.771296  Acc: 0.687500\n",
            "[Epoch 3 Iter 21] Loss: 0.767924  Acc: 0.700000\n",
            "[Epoch 3 Iter 41] Loss: 0.682082  Acc: 0.728125\n",
            "[Epoch 3 Iter 61] Loss: 0.740522  Acc: 0.715625\n",
            "[Epoch 3 Iter 81] Loss: 0.746045  Acc: 0.714063\n",
            "[Epoch 3 Iter 101] Loss: 0.725620  Acc: 0.704688\n",
            "[Epoch 3 Iter 121] Loss: 0.684423  Acc: 0.731250\n",
            "[Epoch 3 Iter 141] Loss: 0.757226  Acc: 0.673438\n",
            "[Epoch 3 Iter 161] Loss: 0.701240  Acc: 0.726562\n",
            "[Epoch 3 Iter 181] Loss: 0.743320  Acc: 0.685937\n",
            "[Epoch 3 Iter 201] Loss: 0.732662  Acc: 0.704688\n",
            "[Epoch 3 Iter 221] Loss: 0.708455  Acc: 0.715625\n",
            "[Epoch 3 Iter 241] Loss: 0.722255  Acc: 0.707812\n",
            "[Epoch 3 Iter 261] Loss: 0.756327  Acc: 0.695312\n",
            "[Epoch 3 Iter 281] Loss: 0.735747  Acc: 0.692187\n",
            "[Epoch 3 Iter 301] Loss: 0.775828  Acc: 0.682813\n",
            "[Epoch 3 Iter 321] Loss: 0.696053  Acc: 0.715625\n",
            "[Epoch 3 Iter 341] Loss: 0.682901  Acc: 0.720313\n",
            "[Epoch 3 Iter 361] Loss: 0.701762  Acc: 0.720313\n",
            "[Epoch 3 Iter 381] Loss: 0.668999  Acc: 0.735938\n",
            "[Epoch 3 Iter 401] Loss: 0.757216  Acc: 0.695312\n",
            "[Epoch 3 Iter 421] Loss: 0.735742  Acc: 0.710938\n",
            "[Epoch 3 Iter 441] Loss: 0.698084  Acc: 0.704688\n",
            "[Epoch 4 Iter 1] Loss: 0.521255  Acc: 0.843750\n",
            "[Epoch 4 Iter 21] Loss: 0.690898  Acc: 0.731250\n",
            "[Epoch 4 Iter 41] Loss: 0.631273  Acc: 0.731250\n",
            "[Epoch 4 Iter 61] Loss: 0.656098  Acc: 0.737500\n",
            "[Epoch 4 Iter 81] Loss: 0.689484  Acc: 0.718750\n",
            "[Epoch 4 Iter 101] Loss: 0.726853  Acc: 0.692187\n",
            "[Epoch 4 Iter 121] Loss: 0.670798  Acc: 0.728125\n",
            "[Epoch 4 Iter 141] Loss: 0.666263  Acc: 0.729688\n",
            "[Epoch 4 Iter 161] Loss: 0.710266  Acc: 0.707812\n",
            "[Epoch 4 Iter 181] Loss: 0.692824  Acc: 0.706250\n",
            "[Epoch 4 Iter 201] Loss: 0.655915  Acc: 0.737500\n",
            "[Epoch 4 Iter 221] Loss: 0.673398  Acc: 0.731250\n",
            "[Epoch 4 Iter 241] Loss: 0.646585  Acc: 0.746875\n",
            "[Epoch 4 Iter 261] Loss: 0.748616  Acc: 0.681250\n",
            "[Epoch 4 Iter 281] Loss: 0.690681  Acc: 0.704688\n",
            "[Epoch 4 Iter 301] Loss: 0.690987  Acc: 0.723437\n",
            "[Epoch 4 Iter 321] Loss: 0.668506  Acc: 0.731250\n",
            "[Epoch 4 Iter 341] Loss: 0.646398  Acc: 0.731250\n",
            "[Epoch 4 Iter 361] Loss: 0.681420  Acc: 0.725000\n",
            "[Epoch 4 Iter 381] Loss: 0.683947  Acc: 0.709375\n",
            "[Epoch 4 Iter 401] Loss: 0.672532  Acc: 0.728125\n",
            "[Epoch 4 Iter 421] Loss: 0.649628  Acc: 0.729688\n",
            "[Epoch 4 Iter 441] Loss: 0.652443  Acc: 0.740625\n",
            "[Epoch 5 Iter 1] Loss: 0.661123  Acc: 0.656250\n",
            "[Epoch 5 Iter 21] Loss: 0.653451  Acc: 0.735938\n",
            "[Epoch 5 Iter 41] Loss: 0.658553  Acc: 0.745313\n",
            "[Epoch 5 Iter 61] Loss: 0.629952  Acc: 0.754687\n",
            "[Epoch 5 Iter 81] Loss: 0.639019  Acc: 0.723437\n",
            "[Epoch 5 Iter 101] Loss: 0.682869  Acc: 0.710938\n",
            "[Epoch 5 Iter 121] Loss: 0.601852  Acc: 0.771875\n",
            "[Epoch 5 Iter 141] Loss: 0.597813  Acc: 0.767188\n",
            "[Epoch 5 Iter 161] Loss: 0.636215  Acc: 0.735938\n",
            "[Epoch 5 Iter 181] Loss: 0.624301  Acc: 0.760938\n",
            "[Epoch 5 Iter 201] Loss: 0.618648  Acc: 0.745313\n",
            "[Epoch 5 Iter 221] Loss: 0.633819  Acc: 0.737500\n",
            "[Epoch 5 Iter 241] Loss: 0.668258  Acc: 0.748437\n",
            "[Epoch 5 Iter 261] Loss: 0.665269  Acc: 0.725000\n",
            "[Epoch 5 Iter 281] Loss: 0.678826  Acc: 0.703125\n",
            "[Epoch 5 Iter 301] Loss: 0.659485  Acc: 0.721875\n",
            "[Epoch 5 Iter 321] Loss: 0.651235  Acc: 0.735938\n",
            "[Epoch 5 Iter 341] Loss: 0.667997  Acc: 0.707812\n",
            "[Epoch 5 Iter 361] Loss: 0.699540  Acc: 0.693750\n",
            "[Epoch 5 Iter 381] Loss: 0.604918  Acc: 0.759375\n",
            "[Epoch 5 Iter 401] Loss: 0.668870  Acc: 0.692187\n",
            "[Epoch 5 Iter 421] Loss: 0.590950  Acc: 0.756250\n",
            "[Epoch 5 Iter 441] Loss: 0.631498  Acc: 0.735938\n",
            "[Epoch 6 Iter 1] Loss: 0.449159  Acc: 0.781250\n",
            "[Epoch 6 Iter 21] Loss: 0.549351  Acc: 0.771875\n",
            "[Epoch 6 Iter 41] Loss: 0.589202  Acc: 0.760938\n",
            "[Epoch 6 Iter 61] Loss: 0.624700  Acc: 0.742188\n",
            "[Epoch 6 Iter 81] Loss: 0.631167  Acc: 0.726562\n",
            "[Epoch 6 Iter 101] Loss: 0.655759  Acc: 0.732812\n",
            "[Epoch 6 Iter 121] Loss: 0.555105  Acc: 0.779687\n",
            "[Epoch 6 Iter 141] Loss: 0.602835  Acc: 0.732812\n",
            "[Epoch 6 Iter 161] Loss: 0.601408  Acc: 0.737500\n",
            "[Epoch 6 Iter 181] Loss: 0.590250  Acc: 0.745313\n",
            "[Epoch 6 Iter 201] Loss: 0.612149  Acc: 0.734375\n",
            "[Epoch 6 Iter 221] Loss: 0.564547  Acc: 0.764062\n",
            "[Epoch 6 Iter 241] Loss: 0.588336  Acc: 0.748437\n",
            "[Epoch 6 Iter 261] Loss: 0.551223  Acc: 0.770312\n",
            "[Epoch 6 Iter 281] Loss: 0.612253  Acc: 0.756250\n",
            "[Epoch 6 Iter 301] Loss: 0.598998  Acc: 0.732812\n",
            "[Epoch 6 Iter 321] Loss: 0.635651  Acc: 0.734375\n",
            "[Epoch 6 Iter 341] Loss: 0.623274  Acc: 0.740625\n",
            "[Epoch 6 Iter 361] Loss: 0.638984  Acc: 0.714063\n",
            "[Epoch 6 Iter 381] Loss: 0.582449  Acc: 0.768750\n",
            "[Epoch 6 Iter 401] Loss: 0.586864  Acc: 0.753125\n",
            "[Epoch 6 Iter 421] Loss: 0.622868  Acc: 0.725000\n",
            "[Epoch 6 Iter 441] Loss: 0.673496  Acc: 0.718750\n",
            "[Epoch 7 Iter 1] Loss: 0.402962  Acc: 0.812500\n",
            "[Epoch 7 Iter 21] Loss: 0.514135  Acc: 0.795312\n",
            "[Epoch 7 Iter 41] Loss: 0.575134  Acc: 0.778125\n",
            "[Epoch 7 Iter 61] Loss: 0.590482  Acc: 0.756250\n",
            "[Epoch 7 Iter 81] Loss: 0.516765  Acc: 0.790625\n",
            "[Epoch 7 Iter 101] Loss: 0.575759  Acc: 0.770312\n",
            "[Epoch 7 Iter 121] Loss: 0.552047  Acc: 0.792188\n",
            "[Epoch 7 Iter 141] Loss: 0.606797  Acc: 0.764062\n",
            "[Epoch 7 Iter 161] Loss: 0.561918  Acc: 0.750000\n",
            "[Epoch 7 Iter 181] Loss: 0.559611  Acc: 0.775000\n",
            "[Epoch 7 Iter 201] Loss: 0.567774  Acc: 0.753125\n",
            "[Epoch 7 Iter 221] Loss: 0.552526  Acc: 0.764062\n",
            "[Epoch 7 Iter 241] Loss: 0.536342  Acc: 0.787500\n",
            "[Epoch 7 Iter 261] Loss: 0.541393  Acc: 0.767188\n",
            "[Epoch 7 Iter 281] Loss: 0.635102  Acc: 0.726562\n",
            "[Epoch 7 Iter 301] Loss: 0.646211  Acc: 0.717187\n",
            "[Epoch 7 Iter 321] Loss: 0.603513  Acc: 0.748437\n",
            "[Epoch 7 Iter 341] Loss: 0.619576  Acc: 0.742188\n",
            "[Epoch 7 Iter 361] Loss: 0.593500  Acc: 0.746875\n",
            "[Epoch 7 Iter 381] Loss: 0.573152  Acc: 0.757812\n",
            "[Epoch 7 Iter 401] Loss: 0.558790  Acc: 0.756250\n",
            "[Epoch 7 Iter 421] Loss: 0.619584  Acc: 0.754687\n",
            "[Epoch 7 Iter 441] Loss: 0.597514  Acc: 0.756250\n",
            "[Epoch 8 Iter 1] Loss: 0.465226  Acc: 0.812500\n",
            "[Epoch 8 Iter 21] Loss: 0.522211  Acc: 0.789062\n",
            "[Epoch 8 Iter 41] Loss: 0.576960  Acc: 0.760938\n",
            "[Epoch 8 Iter 61] Loss: 0.486979  Acc: 0.801562\n",
            "[Epoch 8 Iter 81] Loss: 0.519017  Acc: 0.785937\n",
            "[Epoch 8 Iter 101] Loss: 0.533197  Acc: 0.767188\n",
            "[Epoch 8 Iter 121] Loss: 0.567032  Acc: 0.739062\n",
            "[Epoch 8 Iter 141] Loss: 0.498488  Acc: 0.784375\n",
            "[Epoch 8 Iter 161] Loss: 0.552137  Acc: 0.757812\n",
            "[Epoch 8 Iter 181] Loss: 0.531073  Acc: 0.775000\n",
            "[Epoch 8 Iter 201] Loss: 0.637088  Acc: 0.723437\n",
            "[Epoch 8 Iter 221] Loss: 0.553558  Acc: 0.768750\n",
            "[Epoch 8 Iter 241] Loss: 0.548370  Acc: 0.767188\n",
            "[Epoch 8 Iter 261] Loss: 0.526831  Acc: 0.793750\n",
            "[Epoch 8 Iter 281] Loss: 0.608952  Acc: 0.762500\n",
            "[Epoch 8 Iter 301] Loss: 0.561875  Acc: 0.778125\n",
            "[Epoch 8 Iter 321] Loss: 0.593256  Acc: 0.743750\n",
            "[Epoch 8 Iter 341] Loss: 0.540071  Acc: 0.773438\n",
            "[Epoch 8 Iter 361] Loss: 0.554066  Acc: 0.778125\n",
            "[Epoch 8 Iter 381] Loss: 0.561623  Acc: 0.754687\n",
            "[Epoch 8 Iter 401] Loss: 0.536224  Acc: 0.753125\n",
            "[Epoch 8 Iter 421] Loss: 0.579424  Acc: 0.746875\n",
            "[Epoch 8 Iter 441] Loss: 0.532869  Acc: 0.781250\n",
            "[Epoch 9 Iter 1] Loss: 0.703221  Acc: 0.625000\n",
            "[Epoch 9 Iter 21] Loss: 0.492728  Acc: 0.789062\n",
            "[Epoch 9 Iter 41] Loss: 0.467947  Acc: 0.793750\n",
            "[Epoch 9 Iter 61] Loss: 0.574026  Acc: 0.759375\n",
            "[Epoch 9 Iter 81] Loss: 0.538535  Acc: 0.762500\n",
            "[Epoch 9 Iter 101] Loss: 0.470051  Acc: 0.810937\n",
            "[Epoch 9 Iter 121] Loss: 0.523295  Acc: 0.779687\n",
            "[Epoch 9 Iter 141] Loss: 0.506307  Acc: 0.803125\n",
            "[Epoch 9 Iter 161] Loss: 0.506390  Acc: 0.768750\n",
            "[Epoch 9 Iter 181] Loss: 0.503652  Acc: 0.782813\n",
            "[Epoch 9 Iter 201] Loss: 0.554642  Acc: 0.760938\n",
            "[Epoch 9 Iter 221] Loss: 0.530688  Acc: 0.764062\n",
            "[Epoch 9 Iter 241] Loss: 0.552885  Acc: 0.759375\n",
            "[Epoch 9 Iter 261] Loss: 0.581009  Acc: 0.773438\n",
            "[Epoch 9 Iter 281] Loss: 0.534948  Acc: 0.784375\n",
            "[Epoch 9 Iter 301] Loss: 0.534263  Acc: 0.764062\n",
            "[Epoch 9 Iter 321] Loss: 0.520008  Acc: 0.773438\n",
            "[Epoch 9 Iter 341] Loss: 0.575171  Acc: 0.770312\n",
            "[Epoch 9 Iter 361] Loss: 0.521231  Acc: 0.785937\n",
            "[Epoch 9 Iter 381] Loss: 0.528774  Acc: 0.764062\n",
            "[Epoch 9 Iter 401] Loss: 0.554083  Acc: 0.756250\n",
            "[Epoch 9 Iter 421] Loss: 0.534146  Acc: 0.771875\n",
            "[Epoch 9 Iter 441] Loss: 0.565258  Acc: 0.734375\n",
            "[Epoch 10 Iter 1] Loss: 0.559279  Acc: 0.750000\n",
            "[Epoch 10 Iter 21] Loss: 0.498706  Acc: 0.790625\n",
            "[Epoch 10 Iter 41] Loss: 0.495177  Acc: 0.792188\n",
            "[Epoch 10 Iter 61] Loss: 0.460896  Acc: 0.817187\n",
            "[Epoch 10 Iter 81] Loss: 0.476239  Acc: 0.793750\n",
            "[Epoch 10 Iter 101] Loss: 0.462465  Acc: 0.806250\n",
            "[Epoch 10 Iter 121] Loss: 0.516138  Acc: 0.773438\n",
            "[Epoch 10 Iter 141] Loss: 0.527182  Acc: 0.764062\n",
            "[Epoch 10 Iter 161] Loss: 0.531500  Acc: 0.765625\n",
            "[Epoch 10 Iter 181] Loss: 0.467736  Acc: 0.800000\n",
            "[Epoch 10 Iter 201] Loss: 0.433730  Acc: 0.821875\n",
            "[Epoch 10 Iter 221] Loss: 0.501991  Acc: 0.784375\n",
            "[Epoch 10 Iter 241] Loss: 0.532495  Acc: 0.767188\n",
            "[Epoch 10 Iter 261] Loss: 0.552196  Acc: 0.762500\n",
            "[Epoch 10 Iter 281] Loss: 0.481655  Acc: 0.790625\n",
            "[Epoch 10 Iter 301] Loss: 0.523147  Acc: 0.787500\n",
            "[Epoch 10 Iter 321] Loss: 0.502363  Acc: 0.782813\n",
            "[Epoch 10 Iter 341] Loss: 0.541924  Acc: 0.757812\n",
            "[Epoch 10 Iter 361] Loss: 0.524732  Acc: 0.781250\n",
            "[Epoch 10 Iter 381] Loss: 0.494985  Acc: 0.809375\n",
            "[Epoch 10 Iter 401] Loss: 0.505494  Acc: 0.768750\n",
            "[Epoch 10 Iter 421] Loss: 0.527308  Acc: 0.765625\n",
            "[Epoch 10 Iter 441] Loss: 0.518373  Acc: 0.778125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvu9wUcv1OK_",
        "outputId": "d712286e-91ed-4ce7-b938-f966035c832c"
      },
      "source": [
        "model.load_state_dict(torch.load(\"model\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqM73LRCh0zW"
      },
      "source": [
        "from sklearn.metrics import accuracy_score # normal accuracy\n",
        "from sklearn.metrics import balanced_accuracy_score # used in case of imbalanced data sets, average of recall, from 0 to 1\n",
        "from sklearn.metrics import confusion_matrix # division of performance on the multilabels\n",
        "from sklearn.metrics import cohen_kappa_score # compares model against random prediction, from -1 to 1\n",
        "from sklearn.metrics import classification_report # for multilabel classification, gives precision, recall, f score, support, more\n",
        "target_names = ['Bored', 'Confused','Engaged','frustrated']\n",
        "\n",
        "def print_metrics(y_true, y_pred):\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Balanced Accuracy:\" , balanced_accuracy_score(y_true, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "    print(\"Cohen Kappa Score:\", cohen_kappa_score(y_true, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k46oTQIV7UQk",
        "outputId": "d2adc734-c833-417a-cd7b-bcd09b9937e5"
      },
      "source": [
        "print(testloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7fd815563510>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03sgNp4d7HWX",
        "outputId": "8875a0d1-c7c4-4a08-c594-0ab50acc4ae5"
      },
      "source": [
        "report_every = 10\n",
        "acc, loss = 0, 0\n",
        "cnt = 0\n",
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        X, y = data[0].float().to(device), data[1].to(device)    \n",
        "        # prediction\n",
        "        out = model(X)        \n",
        "        pred = torch.argmax(out, dim=1)\n",
        "\n",
        "        y_true.append(y)\n",
        "        y_pred.append(pred)\n",
        "\n",
        "        cnt += 1\n",
        "\n",
        "        if cnt % report_every == 0:\n",
        "            print(\"[Test] %d / %d batches tested\" % (cnt, testloader.__len__()))        \n",
        "\n",
        "    print(\"[Test] %d / %d batches tested\" % (cnt, testloader.__len__()))\n",
        "    y_true = torch.cat(y_true, dim=0)\n",
        "    y_pred = torch.cat(y_pred, dim=0)\n",
        "    print_metrics(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Test] 10 / 115 batches tested\n",
            "[Test] 20 / 115 batches tested\n",
            "[Test] 30 / 115 batches tested\n",
            "[Test] 40 / 115 batches tested\n",
            "[Test] 50 / 115 batches tested\n",
            "[Test] 60 / 115 batches tested\n",
            "[Test] 70 / 115 batches tested\n",
            "[Test] 80 / 115 batches tested\n",
            "[Test] 90 / 115 batches tested\n",
            "[Test] 100 / 115 batches tested\n",
            "[Test] 110 / 115 batches tested\n",
            "[Test] 115 / 115 batches tested\n",
            "Accuracy: 0.6947023484434736\n",
            "Balanced Accuracy: 0.6117553721544172\n",
            "Confusion Matrix:\n",
            " [[ 776  205  345   43]\n",
            " [  89  316   62   21]\n",
            " [  64  110 1364   21]\n",
            " [  56   67   35   88]]\n",
            "Cohen Kappa Score: 0.5380688100012603\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Bored       0.79      0.57      0.66      1369\n",
            "    Confused       0.45      0.65      0.53       488\n",
            "     Engaged       0.76      0.87      0.81      1559\n",
            "  frustrated       0.51      0.36      0.42       246\n",
            "\n",
            "    accuracy                           0.69      3662\n",
            "   macro avg       0.63      0.61      0.61      3662\n",
            "weighted avg       0.71      0.69      0.69      3662\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clcHav7HGFQf"
      },
      "source": [
        "torch.save(model.state_dict(), \"MyModel\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRazsPzBXvvY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}